# response.created

Source: https://platform.openai.com/docs/api-reference/realtime-beta-server-events/response/created

Returned when a new Response is created. The first event of response creation,
where the response is in an initial state of `in_progress`.

## Properties
- `event_id` (string, required): The unique ID of the server event.
- `type` (string, required): The event type, must be `response.created`. Enum: 'response.created'.
- `response` (object, required): The response resource.
  - `id` (string, optional): The unique ID of the response.
  - `object` (string, optional): The object type, must be `realtime.response`. Enum: 'realtime.response'.
  - `status` (string, optional): The final status of the response (`completed`, `cancelled`, `failed`, or 
    `incomplete`, `in_progress`). Enum: 'completed', 'cancelled', 'failed', 'incomplete', 'in_progress'.
  - `status_details` (object, optional): Additional details about the status.
    - `type` (string, optional): The type of error that caused the response to fail, corresponding 
      with the `status` field (`completed`, `cancelled`, `incomplete`, 
      `failed`). Enum: 'completed', 'cancelled', 'failed', 'incomplete'.
    - `reason` (string, optional): The reason the Response did not complete. For a `cancelled` Response, 
      one of `turn_detected` (the server VAD detected a new start of speech) 
      or `client_cancelled` (the client sent a cancel event). For an 
      `incomplete` Response, one of `max_output_tokens` or `content_filter` 
      (the server-side safety filter activated and cut off the response). Enum: 'turn_detected', 'client_cancelled', 'max_output_tokens', 'content_filter'.
    - `error` (object, optional): A description of the error that caused the response to fail, 
      populated when the `status` is `failed`.
      - `type` (string, optional): The type of error.
      - `code` (string, optional): Error code, if any.
  - `output` (array<object>, optional): The list of output items generated by the response.
  - `metadata` (object | null, optional)
  - `usage` (object, optional): Usage statistics for the Response, this will correspond to billing. A 
    Realtime API session will maintain a conversation context and append new 
    Items to the Conversation, thus output from previous turns (text and 
    audio tokens) will become the input for later turns.
    - `total_tokens` (integer, optional): The total number of tokens in the Response including input and output 
      text and audio tokens.
    - `input_tokens` (integer, optional): The number of input tokens used in the Response, including text and 
      audio tokens.
    - `output_tokens` (integer, optional): The number of output tokens sent in the Response, including text and 
      audio tokens.
    - `input_token_details` (object, optional): Details about the input tokens used in the Response.
      - `cached_tokens` (integer, optional): The number of cached tokens used as input for the Response.
      - `text_tokens` (integer, optional): The number of text tokens used as input for the Response.
      - `image_tokens` (integer, optional): The number of image tokens used as input for the Response.
      - `audio_tokens` (integer, optional): The number of audio tokens used as input for the Response.
      - `cached_tokens_details` (object, optional): Details about the cached tokens used as input for the Response.
        - `text_tokens` (integer, optional): The number of cached text tokens used as input for the Response.
        - `image_tokens` (integer, optional): The number of cached image tokens used as input for the Response.
        - `audio_tokens` (integer, optional): The number of cached audio tokens used as input for the Response.
    - `output_token_details` (object, optional): Details about the output tokens used in the Response.
      - `text_tokens` (integer, optional): The number of text tokens used in the Response.
      - `audio_tokens` (integer, optional): The number of audio tokens used in the Response.
  - `conversation_id` (string, optional): Which conversation the response is added to, determined by the `conversation`
    field in the `response.create` event. If `auto`, the response will be added to
    the default conversation and the value of `conversation_id` will be an id like
    `conv_1234`. If `none`, the response will not be added to any conversation and
    the value of `conversation_id` will be `null`. If responses are being triggered
    by server VAD, the response will be added to the default conversation, thus
    the `conversation_id` will be an id like `conv_1234`.
  - `voice` (string, optional): The voice the model used to respond.
    Current voice options are `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`,
    `shimmer`, and `verse`.
  - `modalities` (array<string>, optional): The set of modalities the model used to respond. If there are multiple modalities,
    the model will pick one, for example if `modalities` is `["text", "audio"]`, the model
    could be responding in either text or audio.
  - `output_audio_format` (string, optional): The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. Enum: 'pcm16', 'g711_ulaw', 'g711_alaw'.
  - `temperature` (number, optional): Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.
  - `max_output_tokens` (integer | string, optional): Maximum number of output tokens for a single assistant response,
    inclusive of tool calls, that was used in this response.
