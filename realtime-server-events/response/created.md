# response.created

Source: https://platform.openai.com/docs/api-reference/realtime-server-events/response/created

Returned when a new Response is created. The first event of response creation,
where the response is in an initial state of `in_progress`.

## Properties
- `event_id` (string, required): The unique ID of the server event.
- `type` (string, required): The event type, must be `response.created`. Enum: 'response.created'.
- `response` (object, required): The response resource.
  - `id` (string, optional): The unique ID of the response, will look like `resp_1234`.
  - `object` (string, optional): The object type, must be `realtime.response`. Enum: 'realtime.response'.
  - `status` (string, optional): The final status of the response (`completed`, `cancelled`, `failed`, or 
    `incomplete`, `in_progress`). Enum: 'completed', 'cancelled', 'failed', 'incomplete', 'in_progress'.
  - `status_details` (object, optional): Additional details about the status.
    - `type` (string, optional): The type of error that caused the response to fail, corresponding 
      with the `status` field (`completed`, `cancelled`, `incomplete`, 
      `failed`). Enum: 'completed', 'cancelled', 'failed', 'incomplete'.
    - `reason` (string, optional): The reason the Response did not complete. For a `cancelled` Response,  one of `turn_detected` (the server VAD detected a new start of speech)  or `client_cancelled` (the client sent a cancel event). For an  `incomplete` Response, one of `max_output_tokens` or `content_filter`  (the server-side safety filter activated and cut off the response). Enum: 'turn_detected', 'client_cancelled', 'max_output_tokens', 'content_filter'.
    - `error` (object, optional): A description of the error that caused the response to fail, 
      populated when the `status` is `failed`.
      - `type` (string, optional): The type of error.
      - `code` (string, optional): Error code, if any.
  - `output` (array<object>, optional): The list of output items generated by the response.
  - `metadata` (object | null, optional)
  - `audio` (object, optional): Configuration for audio output.
    - `output` (object, optional)
      - `format` (object, optional): The format of the output audio.
        - Variant (object):
          - ...
        - Variant (object):
          - ...
        - Variant (object):
          - ...
      - `voice` (string, optional): The voice the model uses to respond. Voice cannot be changed during the
        session once the model has responded with audio at least once. Current
        voice options are `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`,
        `shimmer`, `verse`, `marin`, and `cedar`. We recommend `marin` and `cedar` for
        best quality. Default: `alloy`.
  - `usage` (object, optional): Usage statistics for the Response, this will correspond to billing. A 
    Realtime API session will maintain a conversation context and append new 
    Items to the Conversation, thus output from previous turns (text and 
    audio tokens) will become the input for later turns.
    - `total_tokens` (integer, optional): The total number of tokens in the Response including input and output 
      text and audio tokens.
    - `input_tokens` (integer, optional): The number of input tokens used in the Response, including text and 
      audio tokens.
    - `output_tokens` (integer, optional): The number of output tokens sent in the Response, including text and 
      audio tokens.
    - `input_token_details` (object, optional): Details about the input tokens used in the Response. Cached tokens are tokens from previous turns in the conversation that are included as context for the current response. Cached tokens here are counted as a subset of input tokens, meaning input tokens will include cached and uncached tokens.
      - `cached_tokens` (integer, optional): The number of cached tokens used as input for the Response.
      - `text_tokens` (integer, optional): The number of text tokens used as input for the Response.
      - `image_tokens` (integer, optional): The number of image tokens used as input for the Response.
      - `audio_tokens` (integer, optional): The number of audio tokens used as input for the Response.
      - `cached_tokens_details` (object, optional): Details about the cached tokens used as input for the Response.
        - `text_tokens` (integer, optional): The number of cached text tokens used as input for the Response.
        - `image_tokens` (integer, optional): The number of cached image tokens used as input for the Response.
        - `audio_tokens` (integer, optional): The number of cached audio tokens used as input for the Response.
    - `output_token_details` (object, optional): Details about the output tokens used in the Response.
      - `text_tokens` (integer, optional): The number of text tokens used in the Response.
      - `audio_tokens` (integer, optional): The number of audio tokens used in the Response.
  - `conversation_id` (string, optional): Which conversation the response is added to, determined by the `conversation`
    field in the `response.create` event. If `auto`, the response will be added to
    the default conversation and the value of `conversation_id` will be an id like
    `conv_1234`. If `none`, the response will not be added to any conversation and
    the value of `conversation_id` will be `null`. If responses are being triggered
    automatically by VAD the response will be added to the default conversation
  - `output_modalities` (array<string>, optional): The set of modalities the model used to respond, currently the only possible values are
    `[\"audio\"]`, `[\"text\"]`. Audio output always include a text transcript. Setting the
    output to mode `text` will disable audio output from the model.
  - `max_output_tokens` (integer | string, optional): Maximum number of output tokens for a single assistant response,
    inclusive of tool calls, that was used in this response.
