# Create image

Source: https://platform.openai.com/docs/api-reference/images/create

`POST /v1/images/generations`

Creates an image given a prompt. [Learn more](https://platform.openai.com/docs/guides/images).

## Request body
### application/json
- `prompt` (string, required): A text description of the desired image(s). The maximum length is 32000 characters for the GPT image models, 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.
- `model` (string, optional): The model to use for image generation. One of `dall-e-2`, `dall-e-3`, or a GPT image model (`gpt-image-1`, `gpt-image-1-mini`, `gpt-image-1.5`). Defaults to `dall-e-2` unless a parameter specific to the GPT image models is used. Default: `dall-e-2`.
- `n` (integer, optional): The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported. Default: `1`.
- `quality` (string, optional): The quality of the image that will be generated.
  
  - `auto` (default value) will automatically select the best quality for the given model.
  - `high`, `medium` and `low` are supported for the GPT image models.
  - `hd` and `standard` are supported for `dall-e-3`.
  - `standard` is the only option for `dall-e-2`. Enum: 'standard', 'hd', 'low', 'medium', 'high', 'auto'. Default: `auto`.
- `response_format` (string, optional): The format in which generated images with `dall-e-2` and `dall-e-3` are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter isn't supported for the GPT image models, which always return base64-encoded images. Enum: 'url', 'b64_json'. Default: `url`.
- `output_format` (string, optional): The format in which the generated images are returned. This parameter is only supported for the GPT image models. Must be one of `png`, `jpeg`, or `webp`. Enum: 'png', 'jpeg', 'webp'. Default: `png`.
- `output_compression` (integer, optional): The compression level (0-100%) for the generated images. This parameter is only supported for the GPT image models with the `webp` or `jpeg` output formats, and defaults to 100. Default: `100`.
- `stream` (boolean, optional): Generate the image in streaming mode. Defaults to `false`. See the
  [Image generation guide](https://platform.openai.com/docs/guides/image-generation) for more information.
  This parameter is only supported for the GPT image models. Default: `False`.
- `partial_images` (integer | null, optional)
- `size` (string, optional): The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for the GPT image models, one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`, and one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3`. Enum: 'auto', '1024x1024', '1536x1024', '1024x1536', '256x256', '512x512', '1792x1024', '1024x1792'. Default: `auto`.
- `moderation` (string, optional): Control the content-moderation level for images generated by the GPT image models. Must be either `low` for less restrictive filtering or `auto` (default value). Enum: 'low', 'auto'. Default: `auto`.
- `background` (string, optional): Allows to set transparency for the background of the generated image(s).
  This parameter is only supported for the GPT image models. Must be one of
  `transparent`, `opaque` or `auto` (default value). When `auto` is used, the
  model will automatically determine the best background for the image.
  
  If `transparent`, the output format needs to support transparency, so it
  should be set to either `png` (default value) or `webp`. Enum: 'transparent', 'opaque', 'auto'. Default: `auto`.
- `style` (string, optional): The style of the generated images. This parameter is only supported for `dall-e-3`. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. Enum: 'vivid', 'natural'. Default: `vivid`.
- `user` (string, optional): A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).

## Responses
### 200
OK
#### application/json
- `created` (integer, required): The Unix timestamp (in seconds) of when the image was created.
- `data` (array<object>, optional): The list of generated images.
  - Items:
    - `b64_json` (string, optional): The base64-encoded JSON of the generated image. Returned by default for the GPT image models, and only present if `response_format` is set to `b64_json` for `dall-e-2` and `dall-e-3`.
    - `url` (string, optional): When using `dall-e-2` or `dall-e-3`, the URL of the generated image if `response_format` is set to `url` (default value). Unsupported for the GPT image models.
    - `revised_prompt` (string, optional): For `dall-e-3` only, the revised prompt that was used to generate the image.
- `background` (string, optional): The background parameter used for the image generation. Either `transparent` or `opaque`. Enum: 'transparent', 'opaque'.
- `output_format` (string, optional): The output format of the image generation. Either `png`, `webp`, or `jpeg`. Enum: 'png', 'webp', 'jpeg'.
- `size` (string, optional): The size of the image generated. Either `1024x1024`, `1024x1536`, or `1536x1024`. Enum: '1024x1024', '1024x1536', '1536x1024'.
- `quality` (string, optional): The quality of the image generated. Either `low`, `medium`, or `high`. Enum: 'low', 'medium', 'high'.
- `usage` (object, optional): For `gpt-image-1` only, the token usage information for the image generation.
  - `input_tokens` (integer, required): The number of tokens (images and text) in the input prompt.
  - `total_tokens` (integer, required): The total number of tokens (images and text) used for the image generation.
  - `output_tokens` (integer, required): The number of output tokens generated by the model.
  - `output_tokens_details` (object, optional): The output token details for the image generation.
    - `image_tokens` (integer, required): The number of image output tokens generated by the model.
    - `text_tokens` (integer, required): The number of text output tokens generated by the model.
  - `input_tokens_details` (object, required): The input tokens detailed information for the image generation.
    - `text_tokens` (integer, required): The number of text tokens in the input prompt.
    - `image_tokens` (integer, required): The number of image tokens in the input prompt.
#### text/event-stream
- Schema type: `object`

## Returns
Returns an [image](object.md) object.

## Examples
### Generate image
#### Request (curl)
```bash
curl https://api.openai.com/v1/images/generations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-image-1.5",
    "prompt": "A cute baby sea otter",
    "n": 1,
    "size": "1024x1024"
  }'
```
#### Request (python)
```python
import base64
from openai import OpenAI
client = OpenAI()

img = client.images.generate(
    model="gpt-image-1.5",
    prompt="A cute baby sea otter",
    n=1,
    size="1024x1024"
)

image_bytes = base64.b64decode(img.data[0].b64_json)
with open("output.png", "wb") as f:
    f.write(image_bytes)
```
#### Response
```json
{
  "created": 1713833628,
  "data": [
    {
      "b64_json": "..."
    }
  ],
  "usage": {
    "total_tokens": 100,
    "input_tokens": 50,
    "output_tokens": 50,
    "input_tokens_details": {
      "text_tokens": 10,
      "image_tokens": 40
    }
  }
}
```
### Streaming
#### Request (curl)
```bash
curl https://api.openai.com/v1/images/generations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-image-1.5",
    "prompt": "A cute baby sea otter",
    "n": 1,
    "size": "1024x1024",
    "stream": true
  }' \
  --no-buffer
```
#### Request (python)
```python
from openai import OpenAI

client = OpenAI()

stream = client.images.generate(
    model="gpt-image-1.5",
    prompt="A cute baby sea otter",
    n=1,
    size="1024x1024",
    stream=True
)

for event in stream:
    print(event)
```
#### Response
```json
event: image_generation.partial_image
data: {"type":"image_generation.partial_image","b64_json":"...","partial_image_index":0}

event: image_generation.completed
data: {"type":"image_generation.completed","b64_json":"...","usage":{"total_tokens":100,"input_tokens":50,"output_tokens":50,"input_tokens_details":{"text_tokens":10,"image_tokens":40}}}
```
